{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YBiNijoFD4iJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "df = load_boston()"
      ],
      "metadata": {
        "id": "hmtyUxhgF9RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df.keys()  # Returns all the keys of the dataset dictionary\n"
      ],
      "metadata": {
        "id": "kU93GbBEHmHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cb3cea-e71e-48c6-fe44-06b89c4bdb94"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(df.DESCR)  # Info about the dataset"
      ],
      "metadata": {
        "id": "2mFAja2II-tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston = pd.DataFrame(df.data, columns=df.feature_names)\n",
        "boston.head()"
      ],
      "metadata": {
        "id": "QEt0sUm4RID0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " boston.isnull()"
      ],
      "metadata": {
        "id": "QALDeu8AWAUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " boston['MEDV'] = df.target\n",
        "boston.head()"
      ],
      "metadata": {
        "id": "Iux1AWAlVAKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "isnull returns TRUE or FALSE for each of the cell in the dataform. but we cant go exploring the data for TRUE value if any so we use sum() Function to count with all the cell with true value( i.e nullsell)"
      ],
      "metadata": {
        "id": "M2XK5tlTWceZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " boston.isnull().sum()"
      ],
      "metadata": {
        "id": "VmvlfYtSXArh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = boston.drop('MEDV', axis=1)\n",
        "Y = boston['MEDV']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=5)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfXqbqJvXmXc",
        "outputId": "01b53e6c-5ca5-4aea-f0ac-98f6f86d7c23"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(430, 13)\n",
            "(76, 13)\n",
            "(430,)\n",
            "(76,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.matrics import mean_squared_error\n",
        "\n",
        "## SPLITTING THE DATASHEET INTO TRAIN AND TEST SET TO MAKE SURE THE MODEL WORKS WELL\n",
        " \n",
        "X = boston.drop('MEDV', axis=1)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "QPC5wjIVbeA-",
        "outputId": "59d353fd-150e-4de5-9322-2605c8fc981e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-6ee0816e0562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## SPLITTING THE DATASHEET INTO TRAIN AND TEST SET TO MAKE SURE THE MODEL WORKS WELL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.matrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## FITTING MODEL ON THE TRAINING DATASET\n",
        "lin_model = LinearRegression()\n",
        "  \n",
        "lin_model.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "id": "oQGNEZtyc5Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_predict = lin_model.predict(X_train)\n"
      ],
      "metadata": {
        "id": "KCF4XRl8dZcc"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_predict = lin_model.predict(X_train)\n",
        "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print('RMSE is {}'.format(rmse))\n",
        "print(\"\\n\")\n",
        "\n",
        "# on testing set\n",
        "y_test_predict = lin_model.predict(X_test)\n",
        "rmse = (nq.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
        "\n",
        "print(\"The model performence for testing set\")\n",
        "print('RMSE is {}'.format(rmse))\n"
      ],
      "metadata": {
        "id": "y4JUDM8nd378"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}